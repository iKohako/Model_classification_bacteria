# -*- coding: utf-8 -*-
"""model_resnet50.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I-9XHX8jiOG_SfOZll0oLk6MrZ0hlVkl
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
x_train = np.load('/content/drive/MyDrive/Datagen/x_train.npy')
x_test = np.load('/content/drive/MyDrive/Datagen/x_test.npy')
y_train = np.load('/content/drive/MyDrive/Datagen/y_train.npy')
y_test = np.load('/content/drive/MyDrive/Datagen/y_test.npy')

type(x_train)

type(x_train)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

x_train_scaled = x_train/255
x_test_scaled = x_test/255

x_train_scaled

x_test_scaled

import tensorflow as tf
from tensorflow import keras

num_of_classes = 10

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(224,224,3)),
    keras.layers.Dense(units=100,activation='relu'),
    keras.layers.Dense(units=num_of_classes,activation='softmax')
])

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

model.fit(x_train_scaled,y_train,epochs=10)

from tensorflow.keras import Sequential , models , layers
from tensorflow.keras.layers import Dense , Dropout , Flatten
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras import optimizers

conv_base = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))
conv_base.summary()

num_of_classes = 10

model = models.Sequential()
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.BatchNormalization())
model.add(layers.Dense(128,activation='relu'))
model.add(layers.Dropout(0,5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(64,activation='relu'))
model.add(layers.Dropout(0,5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(num_of_classes,activation='softmax'))

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

num_of_classes = 10

model = models.Sequential()
model.add(conv_base) # Add the conv_base first
model.add(layers.Flatten())
model.add(layers.BatchNormalization())
model.add(layers.Dense(128,activation='relu'))
model.add(layers.Dropout(0.5)) # Change to 0.5 for dropout
model.add(layers.BatchNormalization())
model.add(layers.Dense(64,activation='relu'))
model.add(layers.Dropout(0.5)) # Change to 0.5 for dropout
model.add(layers.BatchNormalization())
model.add(layers.Dense(num_of_classes,activation='softmax'))

# Upsampling layers are not needed as ResNet expects a fixed input size

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy']) # Compile the model before training
history = model.fit(x_train_scaled,y_train,epochs=10,validation_split=0.1)

h = history
plt.plot(h.history['accuracy'])
plt.plot(h.history['val_accuracy'],c='red')
plt.title('Learning Curve')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['train','validation'],loc='upper left')
plt.show()

loss , accuracy = model.evaluate(x_test , y_test)
print(f'loss : {loss} , accuracy : {accuracy * 100}')

pred = np.argmax(model.predict(x_test) , axis = 1)

from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_test , pred))

cf = confusion_matrix(y_test , pred , normalize = 'true')
import seaborn as sns
sns.heatmap(cf , annot = True , cmap = 'crest')
plt.xlabel('Predicted');
plt.ylabel('Actual');